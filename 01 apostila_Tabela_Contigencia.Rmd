---
title: "Análise de Dados Categorizados II - aula 05"
author: "Prof Juliano"
date: "31/03/2020"
output: 
  html_document:
    toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
if(!require(tidyverse)){install.packages("tidyverse")}
if(!require(broom)){install.packages("broom")}
```

Para essa apostila são utilizados os pacotes `tidyverse` e `broom`.

## 1. Teste de Fisher

Na aula em Laboratório, realizamos o Teste Exato de Fisher *na unha*, com os dados de *Uma senhora toma chá* da  seguinte forma:

```{r}
tabela<-data.frame(tomou_leite=c(3,1), tomou_cha=c(1,3))
row.names(tabela)<-c("era_leite", "era_cha")
tabela
```

Para colunas e linhas com valores fixos, ou seja, onde $n_{11}$ determina os valores das outras três células.

$$P_{n_{1,1}}=\frac{\binom{n_{1+}}{n_{11}}\binom{n_{2+}}{n_{+1}-n_{11}}}{\binom{n}{n_{+1}}}$$
Lembrando que:

$$\binom{a}{b}= \frac{a!}{b!(a-b)!} $$
Para testar $H_{0}$: independência, o p-valor é a soma das probabilidade hipergeométricas para os resutlados menos favoráveis para $H_1$ com os valores observados. Para $H_{1}$: $\Theta > 1$, dado os totais marginais, tabelas tendo valores maiores de $n_{11}$ também apresentam maiores razão de chance da amostra:

$$\hat{\Theta}=\frac{n_{11}n_{22}}{n_{12}n_{21}}$$
Portanto, provê evidências mais fortes em favor da hipótese alternativa. O p-valor equivale a probabilidade hipergeométrica da cauda direita, ou que $n_{11}$ é, ao menos, maior do que valor observado.

Realizando a fórmula para o valor da *Senhora toma chá*, temos:

```{r}
n11 <- tabela[1,1]
n12 <- tabela[1,2]
n21 <- tabela[2,1]
n22 <- tabela[2,2]
n1total <- n11 + n12
n2total <- n21 + n22
ntotal1 <- n11 + n21
ntotal <- sum(tabela)
```

Portanto, a probabilidade de que a *senhora* realizasse tal *chute* seria:

```{r}
p_acertar <- factorial(n1total)/
  (factorial(n1total - n11)*factorial(n11))

p_errar <- factorial(n2total)/
  (factorial(n2total - (ntotal1 - n11))*factorial(ntotal1 - n11))

p_possiveis <- factorial(ntotal)/
  (factorial(n1total)*factorial(ntotal-n1total))
  
p_n11 <- (p_acertar*p_errar)/p_possiveis
p_n11
```

Posteriormente, realizamos uma função para descobrirmos as possibilidades dentro de outros chutes, sendo:

```{r}
# construindo funcao

p_nij <- function(i, j, tabela){
  outrac <- ifelse(j==1, 2, 1)
  outral <- ifelse(i==1, 2, 1)
  nij <- tabela[i, j]
  nio <- tabela[i, outrac]
  noj <- tabela[outral, j]
  noo <- tabela[outral, outrac]
  nitotal <- nij + nio
  nototal <- noj + noo
  ntotalj <- nij + noj
  ntotal <- sum(tabela)
  p_acertar <- factorial(nitotal)/
    (factorial(nitotal - nij)*factorial(nij))
  p_errar <- factorial(nototal)/
    (factorial(nototal - (ntotalj - nij))*factorial(ntotalj - nij))
  p_possiveis <- factorial(ntotal)/
    (factorial(nitotal) * factorial(ntotal - nitotal))
  p_nij <- (p_acertar * p_errar) / p_possiveis
  return(p_nij)
}
p_nij(i = 1, j = 1, tabela = tabela)
```

Considerando que os valores possiveis de $n_{11}$ = {0, 1, 2, 3, 4}, com os valores marginais iguais a 4, calculamos as probabilidades de $n_{11}$: 

```{r}
tabela <- data.frame(leite = c(0,4), cha = c(4,0))
row.names(tabela)<-c("leite", "cha"); tabela
P_0 <- p_nij(i = 1, j = 1, tabela = tabela)

tabela <- data.frame(leite = c(1,3), cha = c(3,1))
row.names(tabela)<-c("leite", "cha"); tabela
P_1 <- p_nij(i = 1, j = 1, tabela = tabela)

tabela <- data.frame(leite = c(2,2), cha = c(2,2))
row.names(tabela) <- c("leite", "cha"); tabela
P_2 <- p_nij(i = 1, j = 1, tabela = tabela)

tabela<-data.frame(leite=c(3,1), cha=c(1,3))
row.names(tabela)<-c("leite", "cha"); tabela
P_3 <- p_nij(i = 1, j = 1, tabela = tabela)

tabela<-data.frame(leite=c(4,0), cha=c(0,4))
row.names(tabela)<-c("leite", "cha"); tabela
P_4 <- p_nij(i = 1, j = 1, tabela = tabela)
```
Vendo a tabela com os valores possíveis de $n_{11}$, temos:

```{r}
data.frame(n11 =c(0:4),
           P = c(P_0,P_1,P_2,P_3,P_4))
```


Portanto, a probabilidade de que ela acertasse 3 ou mais xícaras seria:

```{r}
P_3 + P_4
```


No R é possível realizar o teste exato de Fisher com a função `fisher.test()`, existindo três alternativas de testes: `alternative = "greater"`, `alternative = "less"` e `alternative = "two.sided"` (*default*):


```{r}
tabela<-data.frame(leite=c(3,1), cha=c(1,3))
row.names(tabela)<-c("leite", "cha"); tabela
```

Se a *senhora* pode ter acertado 0, 1, 3 ou 4:

```{r}
fisher.test(tabela) # bicaudal
```

Que é igual a: 

```{r}
P_0 + P_1 +  P_3 + P_4
```

```{r}
fisher.test(tabela, alternative = "greater") # tirar 3 ou 4
```

Que é igual a: 

```{r}
P_3 + P_4
```

E para alternativa ser menor do que 3:

```{r}
fisher.test(tabela, alternative = "less") # tirar 0, 1, 2 ou 3
```

Que é igual a: 

```{r}
P_0 + P_1 + P_2 + P_3
```

Como pode ver, o *Odds Ratio* ($OR$) mantém-se o mesmo, pois essa é a *razão de chance* onde:

$$OR =\frac{\frac{P(FalouChá|EraChá)}{P(FalouChá|Era Leite)}}{\frac{P(FalouLeite|EraChá)}{P(FalouLeite|EraLeite)}} = \frac{\frac{3/4}{1/4}}{\frac{1/4}{3/4}} = 9$$
```{r}
((3/4)/(1/4))/((1/4)/(3/4))
```
 E lembrando do que foi colocado acima, como é uma tabela de contigência, o nosso $OR$ é o nosso parãmetro $\hat\Theta$:
 
 
 $$\hat{\Theta}=\frac{n_{11}n_{22}}{n_{12}n_{21}}$$
 
 O *Odds Ratio* da fórmula é diferente do resultado da função `fisher.test()`, pois na função é realizada a *Estimativa de Máxima Verossimilhança* (*MLE: Maximum Likelihood Estimate*) **condicional** (*conditional*) e não a **não condicional** (*unconditional*), que é o *Odds Ratio* calculado diretamente da amostra. 
 
 Levando em consideração uma tabela de contingência 2 x 2, temos:
 
```{r}
tabela<-data.frame(Y1=c("p_11","p_10"),
           Y0=c("p_01","p_00"))
rownames(tabela)<-c("X=1","X=0")
colnames(tabela)<-c("Y=1","Y=0")
tabela
```
 
 
 Onde: 
 
`p_11`: $\hat{p}_{11}$

`p_01`: $\hat{p}_{01}$

`p_10`: $\hat{p}_{10}$

`p_00`: $\hat{p}_{00}$

$\hat{p}_{ij} = n_{ij}/n$ 

Podemos estabelecer que a distribuição da razão de chance  segue uma distribuição aproximadamente normal, com:

$$L = log(\frac{\hat{p}_{11}\hat{p}_{00}}{\hat{p}_{10}\hat{p}_{01}})$$
$$L \sim N(log(OR), \sigma^2)$$ 

Erro Padrão (*standard Error*) segue:

$$SE = \sqrt{\frac{1}{n_{11}}+\frac{1}{n_{01}}+\frac{1}{n_{10}}+\frac{1}{n_{00}}} $$

 Ver [link](https://en.wikipedia.org/wiki/Odds_ratio#Definition_in_terms_of_joint_and_conditional_probabilities)

Você pode explorar como a MLE condicionada é realizada na função `fisher.test()` olhando o seu [código disponível no GitHub](https://github.com/SurajGupta/r-source/blob/master/src/library/stats/R/fisher.test.R). Concluímos que o MLE condicional utiliza distribuição hipergeométrica para o cálculo de $OR$.
 
### Exercício 1

Considerando dois tratamentos de câncer (`Cirurgia` e `Radioterapia`), foi verificado se o crescimento foi controlado ou não (`controlado` e `n_controlado`, respectivamente). Veja tabela:

```{r}
cancer <- data.frame(controlado = c(21, 15),
                     n_controlado = c(2, 3))
row.names(cancer)<-c("Cirurgia", "Radioterapia")
cancer
```


#### a) 
Realize e interprete o resultado do Teste exato de Fisher, onde `alternative = "greater"`

```{r}
fisher.test(cancer, alternative = "greater") 
```

#### b) 
Realize e interprete o resultado do Teste exato de Fisher, onde `alternative = less`

```{r}
fisher.test(cancer, alternative ="less") 
```

#### c) 
Realize e interprete o resultado do Teste exato de Fisher, onde `alternative = two.sided`

```{r}
fisher.test(cancer, alternative = "two.sided")
```

#### d) 
Qual resultado você chega em relação aos tratamentos?


## 2. Estimativa Bayesiana para medidas de associação

Métodos Bayesianos são bem sinceros/diretos para estimativas de medidas de associação em tabelas de contingência. Podemos visualizar isso com duas amostras com distribuição binomial sumarizadas em uma tabela 2 x 2. Assumimos que o número de sucessos $Y_{1}$ na linha 1 tenha uma distribuição binomial com parâmetro $\pi_{1}$ para $n_{1}$ tentativas e $Y_{2}$ sucessos para linha 2, com distribuição binomial com parâmetro $\pi_{2}$ em $n_{2}$ tentativas.

A abordagem conjugada Bayesiana usa distribuição *a priori* beta, onde $beta(\alpha_1,\beta_1)$, para $\pi_1$ e $beta(\alpha_2,\beta_2)$, para $\pi_2$. Comumente, todos os hiperparâmetros com valores iguais a 1 denotam uma distribuição uniforme (veja neste [site](https://seeing-theory.brown.edu/probability-distributions/index.html) a distribuição beta e *brinque* com os hiperparâmetros) ou iguais a 0.5 (*Priori* de [Jeffrey](https://alexanderetz.com/2015/07/25/understanding-bayes-updating-priors-via-the-likelihood/)). 
A escolha de beta como a distribuição *a priori* leva em consideração uma distribuição beta a *posteriori*, sendo distribuição $beta(y_i+\alpha_1, n_i-y_i+\beta_i)$ para $\pi_i$ e $i = \{1,2\}$, a qual induz a uma distribuição *posteriori* das diferenças das proporções, relativo ao risco e razãode chance.

Para construir intervalos *a posteriori* para essas medidas de associação e obter uma performance adequada, uma boa escolha é usar o *Priori* de Jeffrey.


### Exemplo - Pequeno ensaio clínico

Em muitos estudos bioméducis, ao tratarmos de uma doença temos a formação de dois grupos: um placebo (ou tratamento convecional) e o tratamento a ser testado. Ao final, verificamos se o tratamento experimental tende a ter uma resposta melhor do que o convencional. Traduzindo isso de maneira estatística, consideramos que a condição neutra (hipótese nula) é de que $\pi_1 < \pi_2$ e a alternativa é de que $\pi_1 > \pi_2$, onde p-valor é uma medida Bayesiana a posterior para $P(\pi_1 \le \pi_2)$, sendo que $\pi_1$ é probabilidade de sucesso do tratamento a ser testado (tratamento 1) e  $\pi_2$ é probabilidade de sucesso do tratamento convencional (tratamento 2).

Com baixa amostragem, os resultados dependem fortemente da escolha da distribuição *a priori*. O exemplo que faremos será de um teste clínico que utilizou 11 pessoas para o novo tratamento, onde todas obtiveram sucesso e somente um paciente foi alocado ao tratamento convencional e não obteve sucesso. Logo, para o tratamento 1 = ($n_1 = y_1 = 11$) e para tratamento 2 = ($n_2 = 1, y_2 = 0$). A tabela 2 x 2 então fica:

```{r}
cancer <- data.frame(sucesso = c(11, 0),
                     n_sucesso = c(0, 1))
row.names(cancer)<-c("Trata_1", "Trata_convencional")
cancer
```

Uma maneira simples de realizar a aproximação dos intervalos das medidas (razão de chance e diferenças nas proporções) é usando simulações, gerando uma grande quantidade de valores aleatórios (aqui usaremos `n = 100000`) de beta com medidas de $\pi_1$ e $\pi_2$ a posteriori.

Como Probabilidades a priori para $\pi_1$ e $\pi_2$ segue $beta(0.5, 0.5)$:

```{r}
p_priori <- rbeta(100000, shape1 = 0.5, shape2 = 0.5)
hist(p_priori)
```


A distribuição a posteriori sendo $beta(y_1+0.5, n_1 - y_1 + 0.5)$ para $\pi_1$ e $beta(y_2+0.5, n_2 - y_2 + 0.5)$ para $\pi_2$, logo, as simulações apresentarão os seguintes valores:

```{r}
pi_trata1 <- rbeta(100000, 
                   shape1 = cancer[1,1] + 0.5, 
                   shape2 = sum(cancer[1,]) - cancer[1,1] + 0.5) 
pi_trata2 <- rbeta(100000,
                   shape1 = cancer[2,1] + 0.5,
                   shape2 = sum(cancer[2,]) - cancer[2,1] + 0.5)
par(mfrow=c(1,2))
hist(pi_trata1) #
hist(pi_trata2) # 15/18
```

Portanto, temos que a razão de chance para cada simulação será (com intervalo de 95%):

```{r}
razao_chance <- pi_trata1*(1-pi_trata2)/((1-pi_trata1)*pi_trata2)
round(quantile(razao_chance, 
               c(0.025, 0.975)),3) # bicaudal 5% a posterior
```

Probabilidade posterior aproximada $P(\pi_1 < \pi_2)$ (controle melhor que o tratamento convencional):

```{r}
mean(pi_trata1 < pi_trata2)
```

A evidência é bem forte que o tratamento experimental é melhor que o tratamento convencional (p-valor ~ 0.005)


### Exercício 2.

Estudando a relação entre problemas psiquiátricos diagnosticandos (`Psicotico` ou `Neurotico`) e tendências suicidas (`Presente` e `Ausente`), o pesquisador encontrou os seguintes valores:

```{r}
suicidas <- data.frame(Psicotico = c(2, 18), 
                       Neurotico = c(6, 14))
rownames(suicidas) <-c("Presente", "Ausente")
suicidas
```

Aplique uma estimativa bayesiana para medidas de associação, utilizando priori de Jeffrey, para verificar se as tendências suicidas são maiores em um paciente com quadro `Neurotico`.


### Exercício 3

Foi realizado um inventário entre homens e mulheres realizado a seguinte pergunta: *"Você acredita em vida após a morte?"*. Os dados se encontram abaixo:

```{r}
dados <- data.frame(acredito = c(859, 1230),
                    nao_acredito = c(413, 357))
rownames(dados) <- c("masculino", "feminino")
dados
```

#### a) 
Trate os dados como amostras binomiais independentes, aplique uma estimativa bayesiana para medidas de associação, utilizando priori de Jeffrey (beta(0.5, 0.5)). Encontre a média das estimativas a posteriori das probabilidades de se acreditar em vida após a morte

#### b) 
Encontre e interprete (i) o intervalo 95% para as diferenças das proporções e da razão de chance; (ii) a probabilidade a posteriori deu que as mulheres tem uma tendência maior de acreditar em vida após a morte do que homens.

#### c) 
Realize um teste de independência utilizando $\chi^2$. Conclua sobre o teste de independência.

#### d) 
Faça uma comparação entre a realização dos métodos usando estimativa bayesiana e frequentista ($\chi^2$). Os resultados foram diferentes? Qual abordagem mostra-se mais confiável? Por quê? 
